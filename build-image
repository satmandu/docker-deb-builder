#!/bin/bash -e

PROG=$(basename $0)
PROG_DIR=$(dirname $0)

function usage {
    cat <<EOF 1>&2
usage: $PROG [options...] SOURCEDIR_for_scripts
Options (These are optional):
  -i IMAGE  Name of the docker image (including tag) to use as package build environment.
           Default: ${defaultimage} .
  -o DIR    Destination directory to store packages to. 
           Default: ${outdir}.

EOF
    exit 1
}

# function fatal {
#     echo "$PROG: ${1:-"Unknown Error"}" 1>&2
#     exit 1
# }

function abspath {
    echo $(cd "$1" && pwd)
}


###########################################################################

#[ "$#" -eq "0" ] && usage

while getopts "i:o:h" opt; do
    case $opt in
        i)
            image="$OPTARG"
            ;;
        o)
            outdir="$OPTARG"
            ;;
        h)
            usage
            ;;
         -h)
             usage
             ;;
    esac
done

shift $(($OPTIND - 1))

#  This should be the image we want to modify. Note that the only options here are 
#  Ubuntu Bionic & Focal Fossa since Canonical only provides daily build images of
#  those distributions.
default_BASE_DIST="focal"
#  This is the default build host image. 18.04 (bionic), 19.10 (eoan/rolling)
# and 20.04 (dev/focal) builds
#  have been tested. However, non-19.04 images may need to be built separately and 
#  invoked through. e.g.:
# BASE_DIST=bionic ./build-image 
# Note that currently kernel package installation in older build hosts may be unreliable.
# I suggest using this for now to build the kernel packages, which will be used in
# whatever image installation you use:
# JUSTDEBS ./build-image

# Default flags as per:
# https://community.arm.com/developer/tools-software/tools/b/tools-software-ides-blog/posts/compiler-flags-across-architectures-march-mtune-and-mcpu


outdir="${outdir:-output}"

BASE_DIST="${BASE_DIST:-${default_BASE_DIST}}"

if [ "$BASE_DIST" == "bionic" ]; then
    base_url="http://cdimage.ubuntu.com/ubuntu-server/bionic/daily-preinstalled/current/"
    defaultimage="docker-rpi4-imagebuilder-v2:bionic"
    else
    base_url="http://cdimage.ubuntu.com/ubuntu-server/daily-preinstalled/current/"
    defaultimage="docker-rpi4-imagebuilder-v3:focal"
    # There is no rolling/eoan daily-preinstalled image
    BASE_DIST=focal
fi

[ "$BASE_DIST" == "bionic" ] && base_image="${BASE_DIST}-preinstalled-server-arm64+raspi3.img.xz"
[ "$BASE_DIST" == "bionic" ] || base_image="${BASE_DIST}-preinstalled-server-arm64+raspi.img.xz"
base_image_url="${base_url}/${base_image}"
cache_volume=rpi4-imagebuilder-cache

# This is the linux version we want to use:
#kernel_branch=rpi-4.19.y
kernel_branch="${kernel_branch:-rpi-5.15.y}"
kernelgitrepo="${kernelgitrepo:-https://github.com/raspberrypi/linux.git}"

srcdir=${PROG_DIR}
srcdir="${srcdir:-.}"

if [ -n "$image" ]
    then
        echo "Chosen build host image is ${image}."
    else
        image="${image:-${defaultimage}}"
        echo "Build host image defaulting to ${image}."
fi

#docker_args="-it "
# The bash script & copy log if failure setup doesn't work without the "-dt" docker argument.
docker_args="-dt "

# Are we mac or are we linux?
SYSTEM=$(uname)

if [ "$SYSTEM" == "Linux" ]; then
    if grep Ubuntu /etc/issue > /dev/null; then
        if ! (dpkg -l | grep qemu-user-static > /dev/null) ; then
            echo "need to install qemu-user-static"
            sudo apt install qemu-user-static -y
        fi
    fi
fi

BUILDHOST_ARCH=$(uname -m)
docker_args+="-e BUILDHOST_ARCH=${BUILDHOST_ARCH} "
if [ "${BUILDHOST_ARCH}" = "aarch64" ]
    then
        unset BUILDNATIVE
    else
        BUILDNATIVE=1
fi
docker_args+="-e BUILDNATIVE=${BUILDNATIVE} "

# Check that mandatory parameters are valid
#[ !    "$outdir"        ] && fatal "output directory was not given (-o DIR)"
#[ ! -d "$outdir"        ] && fatal "output directory does not exist: $outdir"
[ ! -d "$outdir"        ] && mkdir ${outdir}
#[ !    "${srcdir}"        ] && fatal "source directory not given"
#[ !    "$image"         ] && fatal "docker image name not given (-i IMAGE)"

build_container () {
    echo "Build container ${image} not found."
    if [ "$BASE_DIST" == "bionic" ] || [[ "${image}" =~ bionic ]]; then
        echo "Creating Ubuntu Bionic build container."
        docker build -t ${image} -f Dockerfile-ubuntu-bionic .
    elif [[ "${image}" =~ focal ]] || [[ "${image}" =~ 20.04 ]]; then
        echo "Creating Ubuntu Focal build container."
        docker build -t ${image} -f Dockerfile-ubuntu-focal .
    else
        echo "Creating Ubuntu Stable (Rolling) build container."
        docker build -t ${image} -f Dockerfile-ubuntu-rolling .
    fi
}

#Remove existing build container if it exists.
old_containers=("docker-rpi4-imagebuilder-v4:19.04" "docker-rpi4-imagebuilder-v4:18.04" \
"docker-rpi4-imagebuilder-v3:19.04" "docker-rpi4-imagebuilder-v3:18.04" \
"docker-rpi4-imagebuilder-v2:19.04" "docker-rpi4-imagebuilder-v2:18.04" \
"docker-rpi4-imagebuilder:19.04" "docker-rpi4-imagebuilder:18.04" \
"docker-rpi4-imagebuilder:19.10" "docker-rpi4-imagebuilder-v1:bionic" \
"docker-rpi4-imagebuilder-v1:rolling" "docker-rpi4-imagebuilder-v1:19.10")
for container in ${old_containers[*]};
do
    if [ ! "${container}" = "${image}" ]
    then 
            docker rm -fv ${container} > /dev/null 2>&1 || true
    fi
done

# Create Docker Image if it does not exist.
echo "Creating Build Container ${image} if it does not exist."
docker inspect "${image}" &>/dev/null || build_container
docker inspect "${image}" 2>/dev/null | awk '/RepoTags/{getline; print} /LastTagTime/{print}'

# Needed for loopback to work inside container.
#docker_args+="--cap-add=CAP_MKNOD --device-cgroup-rule='b 7:* rmw' "
docker_args+="-v /dev:/dev --privileged "
#docker_args+="--device /dev/loop0 --device /dev/loop-control --device /dev/mapper/control  \
#--device /dev/mapper/* --cap-add SYS_ADMIN --cap-add CAP_MKNOD --security-opt apparmor:unconfined "

# Check that optional parameters are valid
if [ "$depdir" ]; then
    [ ! -d "$depdir" ] && fatal "dependency directory given but does not exist: $depdir"
    docker_args+="-v $(abspath ${depdir}):/dependencies:ro "
fi

docker_args+="-dt -v $(abspath ${srcdir}):/source-ro:ro -v $(abspath ${outdir}):/output -v $(cd $PROG_DIR; pwd)/in-image-script.sh:/in-image-script.sh:ro "

# Pass current UID and GID to container, so that it can change the
# ownership of output files which are otherwise writen to outdir as
# root
docker_args+="-e USER=$(id -u) -e GROUP=$(id -g) "

# Comment following out if you want to keep container after execution
# for debugging
docker_args+="--rm "

linux_cmd () {
    # This is a hack, but if apps are missing it is more annoying to find them
    # locally for every OS.
    local linux_cmd_args="$1"
    local linux_cmd_docker_args+="-it -e USER=$(id -u) -e GROUP=$(id -g) "
    local linux_cmd_docker_args+="--rm -v $(abspath ${srcdir}):/work "
    docker run ${linux_cmd_docker_args} ${image} /bin/bash -c "touch . \
    && cd /work && ${linux_cmd_args}"
}

check_new_image_hash () {
    echo "* Checking image hash."
    current_output=$(curl --silent ${base_url}/SHA1SUMS)
    current=${current_output%% *}
    if [ "$(command -v sha1sum)" ]; then
        local local_hash_output=$(sha1sum $(abspath ${srcdir})/${base_image}.new)
    else
        local local_hash_output=$(linux_cmd "sha1sum ${base_image}.new")
    fi
    local local=${local_hash_output%% *}
    echo "local: $local"
    echo "current: $current"
    if [ "$local" == "$current" ]; then
        tee $(abspath ${srcdir})/${base_image}.shasum <<EOF
$local
EOF
    echo "* ${base_image} hash verified."
    mv $(abspath ${srcdir})/${base_image}.new $(abspath ${srcdir})/${base_image}
    else
    echo "* Image hash mismatch."
    hashfail=1
    download_base_image
    fi
}

download_base_image () {
        echo "* Downloading ${base_image} ."
        if [ -e "$(abspath ${srcdir})/$base_image" ] && \
        [ -e "$(abspath ${srcdir})/${base_image}.shasum" ] ; then
            [ -e "$(abspath ${srcdir})/${base_image%.xz}" ] && rm \
            "$(abspath ${srcdir})/${base_image%.xz}"
            cp $(abspath ${srcdir})/$base_image \
            $(abspath ${srcdir})/${base_image}.bak 2>/dev/null
        fi
        curl -o $(abspath ${srcdir})/${base_image}.new $base_image_url || curl_fail=1
        check_new_image_hash

        if [ "$curl_fail" ]; then 
            echo "* ${base_image} download failed."
            if [ -e "$(abspath ${srcdir})/${base_image}.bak" ] &&
            [ -e "$(abspath ${srcdir})/${base_image}.shasum" ]; then
                mv $(abspath ${srcdir})/${base_image}.bak \
                $(abspath ${srcdir})/$base_image
                echo "* Restoring existing  ${base_image}"
            fi
        fi
        [ -e "$(abspath ${srcdir})/$base_image" ] && \
        echo "* Now have local ${base_image} ."
}

check_for_current_image () {
    current_output=$(curl --silent ${base_url}/SHA1SUMS)
    current=${current_output%% *}
    local local_hash_output
    if [ "$(command -v sha1sum)" ]; then 
        local_hash_output=$(sha1sum $(abspath ${srcdir})/${base_image})
    else
        local_hash_output=$(linux_cmd "sha1sum ${base_image}")
    fi
    local local=${local_hash_output%% *}
    echo "local: $local"
    echo "current: $current"
    if [ ! "$local" == "$current" ]; then
        echo "Local base image sha1sum is:"
        echo $local
        echo "Remote base image shasum is:"
        echo $current
        echo "* New base image available."
        echo "* Trying to get current base image."
        download_base_image && rm -rf "$(abspath ${srcdir:?})/${base_image%.xz}" || true
        [ "$curl_fail" ] && "* Download failed. Using existing image." || \
            echo ""
        else
            echo "* Base image file is current."
        fi
        
}

if [ ! -f $(abspath ${srcdir})/$base_image ] && [ ! -n "$JUSTDEBS" ]; then
        download_base_image
    else
        [ ! -n "$JUSTDEBS" ] && check_for_current_image
fi

if [ ! -f "$(abspath ${srcdir})/${base_image%.xz}" ] && [ ! -n "$JUSTDEBS" ]
    then 
        cd $(abspath ${srcdir})
        echo "* Extracting $(abspath ${srcdir})/${base_image%.xz} ."
        if [ "$(command -v xz)" ]; then
            xz -vdk $(abspath ${srcdir})/${base_image}
        else
            linux_cmd "xz -vdk ${base_image}"
        fi
    else
    echo "* Base image already extracted."
fi

#Send in linux repo environment variables:
docker_args+="-e kernel_branch=${kernel_branch} -e kernelgitrepo=${kernelgitrepo} "

# For ccache
#docker_args+="-e CCACHE_DIR=/ccache --volumes-from ccache -v ccache:/ccache "
docker_args+="-e CCACHE_DIR=/cache/ccache -v $cache_volume:/cache "
# Store apt-cache on cache volume too
docker_args+="-e src_cache=/cache/src_cache "
# Store remote src cache on ccache volume too
docker_args+="-e apt_cache=/cache/apt_cache "
# Set workdir. This is useful if we need to shell in to debug.
docker_args+="-e workdir=/build/source "

# Send in base image environment variables:
docker_args+="-e base_url=${base_url} "
docker_args+="-e base_image=${base_image} "
docker_args+="-e BASE_DIST=${BASE_DIST} "

# Should we enable the arbitrary wait flag?
[ -n "$ARBITRARY_WAIT" ] && docker_args+="-e ARBITRARY_WAIT=${ARBITRARY_WAIT} "
# Send in CFLAGS if they are provided.
[ -n "$CFLAGS" ] && docker_args+="-e CFLAGS=${CFLAGS} "
# Re-fetch all git trees to cache
[ -n "$CLEAN_GIT" ] && docker_args+="-e CLEAN_GIT=${CLEAN_GIT} "
# DEBUG?
[ -n "$DEBUG" ] && docker_args+="-e DEBUG=${DEBUG} "
# Is an email local variable set?
[ -n "$EMAIL" ] && docker_args+="-e EMAIL=${EMAIL} "
# Just make kerneldebs?
[ -n "$JUSTDEBS" ] && docker_args+="-e JUSTDEBS=${JUSTDEBS} "
[ ! -n "$JUSTDEBS" ] && docker_args+="-v $(abspath ${srcdir})/$base_image:/$base_image "
# Pass in kerneldef if it exists
[ -n "$KERNELDEF" ] && docker_args+="-e KERNELDEF=${KERNELDEF} "
# If lucky
[ -n "$MOAR_RAM" ] && docker_args+="--tmpfs /build/source/rpi-linux:exec --tmpfs /build/source/kernel-build:exec "
# No Ethernet LEDs?
[ -n "$NOETHLED" ] && docker_args+="-e NOETHLED=${NOETHLED} "
# package RPI USERLAND
[ -n "$PKGUSERLAND" ] && docker_args+="-e PKGUSERLAND=${PKGUSERLAND} "
# copy out uncompressed images
[ -n "$RAWIMAGE" ] && docker_args+="-e RAWIMAGE=${RAWIMAGE} "
# Request kernel rebuild?
[ -n "$REBUILD" ] && docker_args+="-e REBUILD=${REBUILD} "
# Let XZ be disabled by default.
[ -n "$XZ" ] && docker_args+="-e XZ=${XZ} "
# Build zfs modules if asked.
[ -n "$ZFS" ] && docker_args+="-e ZFS=${ZFS} "
# Build only UBOOT
[ -n "$UBOOTONLY" ] && docker_args+="-e UBOOTONLY=${UBOOTONLY} "
# Pass in ubootdef if it exists
[ -n "$UBOOTDEF" ] && docker_args+="-e UBOOTDEF=${UBOOTDEF} "

# Make some tmpfs mounts for obvious temp folders
docker_args+="--tmpfs /flag --tmpfs /tmp "

# Send in columns for display.
shopt -s checkwinsize 
size=$(stty size) 
lines=${size% *}
console_cols=${size#* }
docker_args+="-e COLS=${console_cols} "

# Export container id
cidfile="$(cd $PROG_DIR; pwd)/build.cid"
docker_args+="--cidfile=$cidfile "

# If the build script fails, the log is still copied out.
startcmd='/in-image-script.sh ;  [ -e "/tmp/build.log" ] && (ls -crGg /flag > /tmp/build_fail_status.log ; grep "" /flag/* >> /tmp/build_fail_status.log ; pstree -p >> /tmp/build_fail_status.log ; mv /tmp/build.log /tmp/build_fail.log; cp /tmp/*.log /output/ ; chown $USER:$GROUP /output/*.log;  )  || exit 0'
# Clear old build failure log file.
rm -f $outdir/build_fail.log
rm -rf $outdir/build_fail_status.log
rm -rf $outdir/*.install.log
rm -rf $outdir/*.compile.log

# Create Docker ccache volume if it does not exist as per https://stackoverflow.com/revisions/39652117/2
echo "Creating docker cache volume $cache_volume if it does not exist."
docker volume create --name $cache_volume

# docker create -v /mnt/ccache:/ccache --name ccache $image
echo -e "\nRunning build in docker:"
echo -e "rm -f $cidfile ; docker run $docker_args $image /bin/bash -c \"$startcmd\"\n"
rm -f $cidfile ; docker run $docker_args $image /bin/bash -c "$startcmd"
build_cid=$(cat $cidfile)
echo -e "\n"

# Now lower priority of container.
# From https://unix.stackexchange.com/posts/317605/revisions

# No idea what to do if not macos or Linux.
PID_LIST=
[ "$SYSTEM" == "Darwin" ] && PID_LIST=$(pgrep com.docker.hyperkit)
if [ "$SYSTEM" == "Linux" ]; then
    container_pid=$(pgrep ${PROG%.*})
    findpids() {
            for pid in /proc/$1/task/* ; do
                    pid="$(basename "$pid")"
                    PID_LIST="$PID_LIST$pid "
                    for cpid in $(cat /proc/$1/task/$pid/children) ; do
                            findpids $cpid
                    done
            done
    }

    findpids "$container_pid"
fi

echo "Using sudo to renice build container to lowest priority:"
echo "(Some renices are expected to fail.)"
sudo renice -n 20 -p $PID_LIST &> /dev/null || true
echo -e "Note that the command to open a shell into this docker instance would be:\n"
echo -e "docker exec -it ${build_cid} /bin/bash\n"
echo -e "Or run ./shellbuild from this directory.\n"

echo "Tailing build log:"
#tail_log_cmd="docker exec -it $build_cid /bin/bash -c 'tail -F /tmp/build.log --pid=\$(cat /flag/main)'"
tail_log_cmd="docker exec -it $build_cid /source-ro/scripts/taillog.sh"

echo ""
exec /bin/bash -c "${tail_log_cmd}; [ -e ${outdir}/build_fail.log ] && echo -e '🤔 Build failed. Tailing ${outdir}/build_fail.log :   😬\n\r' && tail ${outdir}/build_fail.log"
